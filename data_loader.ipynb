{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import copy\n",
    "import h5py\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from utility import save_numpy_to_h5_dataset, load_h5_dataset, single_frame_to_numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from models import VAE\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below download ABIDE images one by one and encode it to the latent space via the variational encoder.\n",
    "The whole dataset is too big for me to download as a whole, hence such a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing pretrained Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = VAE()\n",
    "net.cuda()\n",
    "net.load_state_dict(torch.load(\"VAE_80_epochs.pt\")) #loading weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] == 3:\n",
    "    from urllib.request import urlopen\n",
    "else:\n",
    "    from urllib import urlopen\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import BytesIO as StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('images/abide_file_names.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    file_names = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n",
      "no_filename_func_minimal.nii cannot be obtained.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(file_names)):\n",
    "    try:\n",
    "        url = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/func_minimal/' + file_names[i][0] + '_func_minimal.nii.gz'\n",
    "        outFilePath = file_names[i][0] + '_func_minimal.nii'\n",
    "        response = urlopen(url)\n",
    "        compressedFile = StringIO(response.read())\n",
    "        decompressedFile = gzip.GzipFile(fileobj=compressedFile)\n",
    "\n",
    "        with open('downloaded/' + outFilePath, 'wb') as outfile:\n",
    "            outfile.write(decompressedFile.read())\n",
    "            \n",
    "        img = nib.load('downloaded/' + outFilePath)    \n",
    "        frames = img.dataobj.shape[3] #number of \"frames\" for a given example    \n",
    "            \n",
    "        Xs = []\n",
    "        for j in range(frames):\n",
    "            img_numpy = single_frame_to_numpy(img,j)\n",
    "            img_torch = torch.from_numpy(img_numpy) #convert to torch tensor\n",
    "            encoded = net.encode(Variable(img_torch.cuda())) #generate latent code (60 vbles) through the variational encoder \n",
    "            encoded_numpy =  torch.cat((encoded[0].data[0],encoded[1].data[0])).cpu().numpy()\n",
    "            encoded_numpy = np.expand_dims(encoded_numpy, axis=0)\n",
    "            Xs.append(encoded_numpy)\n",
    "\n",
    "        Xa = np.vstack(Xs)\n",
    "        save_numpy_to_h5_dataset('encoded_images/' + file_names[i][0], Xa)\n",
    "        os.remove('downloaded/' + outFilePath) #delete nii file            \n",
    "            \n",
    "    except:\n",
    "        outFilePath = file_names[i][0] + '_func_minimal.nii'\n",
    "        print(outFilePath + ' cannot be obtained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outFilePath = 'Pitt_0050010' + '_func_minimal.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = nib.load('images/' + outFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = img.dataobj.shape[3] #number of \"frames\" for a given example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = []\n",
    "for j in range(frames):\n",
    "          \n",
    "    img_numpy = single_frame_to_numpy(img,j)\n",
    "    img_torch = torch.from_numpy(img_numpy) #convert to torch tensor\n",
    "    encoded = net.encode(Variable(img_torch.cuda())) #generate latent code (60 vbles) through the variational encoder \n",
    "    encoded_numpy =  torch.cat((encoded[0].data[0],encoded[1].data[0])).cpu().numpy()\n",
    "    encoded_numpy = np.expand_dims(encoded_numpy, axis=0)\n",
    "    Xs.append(encoded_numpy)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (Xs[181])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xa = np.vstack(Xs)\n",
    "save_large_dataset('encoded_images/testowy_plik', Xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.remove('encoded_images/testowy_plik.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
