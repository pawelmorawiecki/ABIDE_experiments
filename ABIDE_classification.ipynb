{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from utility import save_numpy_to_h5_dataset, load_h5_dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification model with GRU. The code for generated datasets is below. No success with this model (convergence on training set easily obtained, for validation set basically random results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRU_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(GRU_model, self).__init__()\n",
    "        \n",
    "        #input shape to GRU (batch, sequence, features)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, 2) \n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        #output shape (batch, sequence, features)\n",
    "        output = F.dropout(output[:,-1,:], p=0.2, training=self.training)\n",
    "        output = self.linear(output)\n",
    "        #output = self.linear(output[:,-1,:]) #output for binary classification calculated from the final hidden state\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 60\n",
    "HIDDEN_SIZE = 100\n",
    "SEQUENCE_LENGTH = 39\n",
    "CUDA = True\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = load_h5_dataset('X.h5')\n",
    "Y = load_h5_dataset('Y.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034, 39, 60)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100) #seed fixed for reproducibility\n",
    "mask = np.random.rand(len(X)) < 0.9  #array of boolean variables\n",
    "\n",
    "training_images = X[mask]\n",
    "training_labels = Y[mask]\n",
    "\n",
    "validation_images = X[~mask]\n",
    "validation_labels = Y[~mask]\n",
    "\n",
    "training_images = torch.from_numpy(training_images) #convert to torch tensor\n",
    "training_labels = torch.from_numpy(training_labels) #convert to torch tensor\n",
    "\n",
    "validation_images = torch.from_numpy(validation_images) #convert to torch tensor\n",
    "validation_labels = torch.from_numpy(validation_labels) #convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_labels = training_labels.long()\n",
    "validation_labels = validation_labels.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(training_images, training_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "validation_dataset = torch.utils.data.TensorDataset(validation_images, validation_labels)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = GRU_model(INPUT_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "net.cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.725\n",
      "Epoch 1, validation loss: 0.697\n",
      "Epoch 2, loss: 0.701\n",
      "Epoch 2, validation loss: 0.697\n",
      "Epoch 3, loss: 0.706\n",
      "Epoch 3, validation loss: 0.697\n",
      "Epoch 4, loss: 0.701\n",
      "Epoch 4, validation loss: 0.699\n",
      "Epoch 5, loss: 0.698\n",
      "Epoch 5, validation loss: 0.697\n",
      "Epoch 6, loss: 0.712\n",
      "Epoch 6, validation loss: 0.696\n",
      "Epoch 7, loss: 0.700\n",
      "Epoch 7, validation loss: 0.695\n",
      "Epoch 8, loss: 0.697\n",
      "Epoch 8, validation loss: 0.700\n",
      "Epoch 9, loss: 0.700\n",
      "Epoch 9, validation loss: 0.698\n",
      "Epoch 10, loss: 0.697\n",
      "Epoch 10, validation loss: 0.696\n",
      "Epoch 11, loss: 0.695\n",
      "Epoch 11, validation loss: 0.695\n",
      "Epoch 12, loss: 0.704\n",
      "Epoch 12, validation loss: 0.697\n",
      "Epoch 13, loss: 0.705\n",
      "Epoch 13, validation loss: 0.698\n",
      "Epoch 14, loss: 0.697\n",
      "Epoch 14, validation loss: 0.697\n",
      "Epoch 15, loss: 0.699\n",
      "Epoch 15, validation loss: 0.698\n",
      "Epoch 16, loss: 0.697\n",
      "Epoch 16, validation loss: 0.695\n",
      "Epoch 17, loss: 0.695\n",
      "Epoch 17, validation loss: 0.700\n",
      "Epoch 18, loss: 0.687\n",
      "Epoch 18, validation loss: 0.697\n",
      "Epoch 19, loss: 0.691\n",
      "Epoch 19, validation loss: 0.699\n",
      "Epoch 20, loss: 0.692\n",
      "Epoch 20, validation loss: 0.698\n",
      "Epoch 21, loss: 0.685\n",
      "Epoch 21, validation loss: 0.705\n",
      "Epoch 22, loss: 0.688\n",
      "Epoch 22, validation loss: 0.698\n",
      "Epoch 23, loss: 0.695\n",
      "Epoch 23, validation loss: 0.710\n",
      "Epoch 24, loss: 0.694\n",
      "Epoch 24, validation loss: 0.699\n",
      "Epoch 25, loss: 0.689\n",
      "Epoch 25, validation loss: 0.699\n",
      "Epoch 26, loss: 0.691\n",
      "Epoch 26, validation loss: 0.700\n",
      "Epoch 27, loss: 0.688\n",
      "Epoch 27, validation loss: 0.706\n",
      "Epoch 28, loss: 0.687\n",
      "Epoch 28, validation loss: 0.703\n",
      "Epoch 29, loss: 0.691\n",
      "Epoch 29, validation loss: 0.704\n",
      "Epoch 30, loss: 0.687\n",
      "Epoch 30, validation loss: 0.700\n",
      "Epoch 31, loss: 0.689\n",
      "Epoch 31, validation loss: 0.704\n",
      "Epoch 32, loss: 0.692\n",
      "Epoch 32, validation loss: 0.700\n",
      "Epoch 33, loss: 0.687\n",
      "Epoch 33, validation loss: 0.708\n",
      "Epoch 34, loss: 0.684\n",
      "Epoch 34, validation loss: 0.701\n",
      "Epoch 35, loss: 0.694\n",
      "Epoch 35, validation loss: 0.703\n",
      "Epoch 36, loss: 0.681\n",
      "Epoch 36, validation loss: 0.703\n",
      "Epoch 37, loss: 0.687\n",
      "Epoch 37, validation loss: 0.703\n",
      "Epoch 38, loss: 0.681\n",
      "Epoch 38, validation loss: 0.706\n",
      "Epoch 39, loss: 0.690\n",
      "Epoch 39, validation loss: 0.704\n",
      "Epoch 40, loss: 0.692\n",
      "Epoch 40, validation loss: 0.702\n",
      "Epoch 41, loss: 0.690\n",
      "Epoch 41, validation loss: 0.703\n",
      "Epoch 42, loss: 0.679\n",
      "Epoch 42, validation loss: 0.715\n",
      "Epoch 43, loss: 0.681\n",
      "Epoch 43, validation loss: 0.702\n",
      "Epoch 44, loss: 0.686\n",
      "Epoch 44, validation loss: 0.702\n",
      "Epoch 45, loss: 0.682\n",
      "Epoch 45, validation loss: 0.702\n",
      "Epoch 46, loss: 0.681\n",
      "Epoch 46, validation loss: 0.703\n",
      "Epoch 47, loss: 0.679\n",
      "Epoch 47, validation loss: 0.705\n",
      "Epoch 48, loss: 0.676\n",
      "Epoch 48, validation loss: 0.702\n",
      "Epoch 49, loss: 0.677\n",
      "Epoch 49, validation loss: 0.703\n",
      "Epoch 50, loss: 0.679\n",
      "Epoch 50, validation loss: 0.708\n",
      "Epoch 51, loss: 0.685\n",
      "Epoch 51, validation loss: 0.705\n",
      "Epoch 52, loss: 0.683\n",
      "Epoch 52, validation loss: 0.712\n",
      "Epoch 53, loss: 0.676\n",
      "Epoch 53, validation loss: 0.716\n",
      "Epoch 54, loss: 0.675\n",
      "Epoch 54, validation loss: 0.704\n",
      "Epoch 55, loss: 0.677\n",
      "Epoch 55, validation loss: 0.704\n",
      "Epoch 56, loss: 0.677\n",
      "Epoch 56, validation loss: 0.704\n",
      "Epoch 57, loss: 0.674\n",
      "Epoch 57, validation loss: 0.705\n",
      "Epoch 58, loss: 0.677\n",
      "Epoch 58, validation loss: 0.708\n",
      "Epoch 59, loss: 0.673\n",
      "Epoch 59, validation loss: 0.706\n",
      "Epoch 60, loss: 0.678\n",
      "Epoch 60, validation loss: 0.711\n",
      "Epoch 61, loss: 0.671\n",
      "Epoch 61, validation loss: 0.710\n",
      "Epoch 62, loss: 0.671\n",
      "Epoch 62, validation loss: 0.707\n",
      "Epoch 63, loss: 0.673\n",
      "Epoch 63, validation loss: 0.706\n",
      "Epoch 64, loss: 0.673\n",
      "Epoch 64, validation loss: 0.732\n",
      "Epoch 65, loss: 0.685\n",
      "Epoch 65, validation loss: 0.714\n",
      "Epoch 66, loss: 0.671\n",
      "Epoch 66, validation loss: 0.715\n",
      "Epoch 67, loss: 0.674\n",
      "Epoch 67, validation loss: 0.718\n",
      "Epoch 68, loss: 0.669\n",
      "Epoch 68, validation loss: 0.712\n",
      "Epoch 69, loss: 0.670\n",
      "Epoch 69, validation loss: 0.712\n",
      "Epoch 70, loss: 0.671\n",
      "Epoch 70, validation loss: 0.716\n",
      "Epoch 71, loss: 0.669\n",
      "Epoch 71, validation loss: 0.714\n",
      "Epoch 72, loss: 0.668\n",
      "Epoch 72, validation loss: 0.714\n",
      "Epoch 73, loss: 0.666\n",
      "Epoch 73, validation loss: 0.711\n",
      "Epoch 74, loss: 0.664\n",
      "Epoch 74, validation loss: 0.713\n",
      "Epoch 75, loss: 0.671\n",
      "Epoch 75, validation loss: 0.730\n",
      "Epoch 76, loss: 0.668\n",
      "Epoch 76, validation loss: 0.723\n",
      "Epoch 77, loss: 0.663\n",
      "Epoch 77, validation loss: 0.715\n",
      "Epoch 78, loss: 0.663\n",
      "Epoch 78, validation loss: 0.718\n",
      "Epoch 79, loss: 0.664\n",
      "Epoch 79, validation loss: 0.718\n",
      "Epoch 80, loss: 0.659\n",
      "Epoch 80, validation loss: 0.717\n",
      "Epoch 81, loss: 0.666\n",
      "Epoch 81, validation loss: 0.743\n",
      "Epoch 82, loss: 0.667\n",
      "Epoch 82, validation loss: 0.724\n",
      "Epoch 83, loss: 0.660\n",
      "Epoch 83, validation loss: 0.736\n",
      "Epoch 84, loss: 0.672\n",
      "Epoch 84, validation loss: 0.726\n",
      "Epoch 85, loss: 0.661\n",
      "Epoch 85, validation loss: 0.726\n",
      "Epoch 86, loss: 0.658\n",
      "Epoch 86, validation loss: 0.726\n",
      "Epoch 87, loss: 0.660\n",
      "Epoch 87, validation loss: 0.727\n",
      "Epoch 88, loss: 0.649\n",
      "Epoch 88, validation loss: 0.724\n",
      "Epoch 89, loss: 0.651\n",
      "Epoch 89, validation loss: 0.731\n",
      "Epoch 90, loss: 0.641\n",
      "Epoch 90, validation loss: 0.736\n",
      "Epoch 91, loss: 0.648\n",
      "Epoch 91, validation loss: 0.761\n",
      "Epoch 92, loss: 0.656\n",
      "Epoch 92, validation loss: 0.741\n",
      "Epoch 93, loss: 0.654\n",
      "Epoch 93, validation loss: 0.738\n",
      "Epoch 94, loss: 0.646\n",
      "Epoch 94, validation loss: 0.742\n",
      "Epoch 95, loss: 0.648\n",
      "Epoch 95, validation loss: 0.780\n",
      "Epoch 96, loss: 0.650\n",
      "Epoch 96, validation loss: 0.731\n",
      "Epoch 97, loss: 0.652\n",
      "Epoch 97, validation loss: 0.735\n",
      "Epoch 98, loss: 0.647\n",
      "Epoch 98, validation loss: 0.740\n",
      "Epoch 99, loss: 0.647\n",
      "Epoch 99, validation loss: 0.743\n",
      "Epoch 100, loss: 0.643\n",
      "Epoch 100, validation loss: 0.756\n"
     ]
    }
   ],
   "source": [
    "# TRAINING #\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):  \n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for j, data in enumerate(train_loader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            batch_length = len(inputs) #length of the current batch\n",
    "            \n",
    "            # wrap them in Variable\n",
    "            if (CUDA):\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            hidden_0 = Variable(torch.zeros((1,batch_length,HIDDEN_SIZE)).cuda()) # !!! zrobic if jesli nie ma CUDA\n",
    "            output = net(inputs,hidden_0)\n",
    "                    \n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss.data[0]*batch_length\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    print('Epoch %d, loss: %.3f' % (epoch + 1, running_loss / len(training_images)))     \n",
    "    \n",
    "    \n",
    "    #VALIDATION\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    for j, data in enumerate(validation_loader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            batch_length = len(inputs) #length of the current batch\n",
    "            \n",
    "            # wrap them in Variable\n",
    "            if (CUDA):\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # forward\n",
    "            hidden_0 = Variable(torch.zeros((1,batch_length,HIDDEN_SIZE)).cuda()) # !!! zrobic if jesli nie ma CUDA\n",
    "            output = net(inputs,hidden_0)\n",
    "                    \n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss.data[0]*batch_length\n",
    "            \n",
    "    print('Epoch %d, validation loss: %.3f' % (epoch + 1, running_loss / len(validation_images)))     \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dataset (one patient - one sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utility import save_numpy_to_h5_dataset, load_h5_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv', delimiter=',')\n",
    "d = {} #dictionary filename: label\n",
    "for i in range(len(df.values)):\n",
    "    d[df.values[i][6]] = df.values[i][7] - 1 # originally in csv file labels are denoted as 1 and 2, hence minus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 39\n",
    "LATENT_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indir = 'encoded_images/'\n",
    "for root, dirs, filenames in os.walk(indir):\n",
    "    X = np.zeros((len(filenames),SEQUENCE_LENGTH,LATENT_SIZE))\n",
    "    Y = np.zeros(len(filenames))\n",
    "  \n",
    "    for i,file in enumerate(filenames,0):\n",
    "        image = load_h5_dataset(indir+file)\n",
    "        X[i] = image[0:SEQUENCE_LENGTH,:]\n",
    "        Y[i] = d[file[:-3]] #take the corresponding label from dictionary d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_numpy_to_h5_dataset('X',X)\n",
    "save_numpy_to_h5_dataset('Y',Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dataset (one patient - multiple sequences, each with 39 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv', delimiter=',')\n",
    "d = {} #dictionary filename: label\n",
    "for i in range(len(df.values)):\n",
    "    d[df.values[i][6]] = df.values[i][7] - 1 # originally in csv file labels are denoted as 1 and 2, hence minus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 39\n",
    "LATENT_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = []  #list of np arrays\n",
    "Ys = []  #list of labels\n",
    "indir = 'encoded_images/'\n",
    "for root, dirs, filenames in os.walk(indir):\n",
    "  \n",
    "    for i,file in enumerate(filenames,0):\n",
    "        image = load_h5_dataset(indir+file)\n",
    "        \n",
    "        for j in range(image.shape[0]//SEQUENCE_LENGTH):\n",
    "            x = image[j*SEQUENCE_LENGTH:(j+1)*SEQUENCE_LENGTH,:]\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            Xs.append(x)\n",
    "            \n",
    "            y = d[file[:-3]] #take the corresponding label from dictionary d\n",
    "            Ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.vstack(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.vstack(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_numpy_to_h5_dataset('X_multi',X)\n",
    "save_numpy_to_h5_dataset('Y_multi',Y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
